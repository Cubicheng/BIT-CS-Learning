计算机体系结构和组成原理

> 2023.5 lbw
>
> 加*为很可能出题的重点，以当年考试来看，这个提纲中的内容有些过于详细了
>
> 寻址 huffman编码 片选 cache 流水线 中断
>
> 取指令的公共操作：`(PC)->MAR`；`READ`；`M(MAR)->MDR->IR`；`(PC)+1->PC`
>
> 中断的操作：
>
> 1. `0->MAR`，将特定地址0送至MAR；如果要把断点存入堆栈，则改为`SP->MAR`
> 2. `(PC)->MDR`，将PC内容送至MDR
> 3. `Write`，启动存储器写操作
> 4. `MDR->M(MAR)`，将MDR的内容写入MAR指示的主存单元
> 5. `向量地址->PC`， 把向量地址形成部件的输出送入PC，为转入中断服务程序做准备
> 6. `0->EINT`，关中断，将中断允许触发器清0
>
> 指令并行度为$(m,n)$，$k$段流水线的超标量超流水线处理机执行$N$条指令所用的时间为$\large T(m,n)=(k+\frac{N-m}{mn})\Delta t$，加速比为$\large S(m,n)=\frac{mn(k+N-1)}{mnk+N-m}$
>
> ![image-20230622191451868](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221914961.png)

# Chapter 1 概论

> 重点内容：
>
> - 存储程序概念、计算机硬件组成
> - 计算机系统的层次结构
> - 计算机系统结构的定义及研究对象
> - 计算机系统结构、组成、实现三者的区别与相互联系
> - 计算机系统设计的主要方法（由中间开始设计）
> -  Amdahl定律和CPU性能公式
> - 解决软件可移植性的三种方法
> - 系统结构中的并行性、并行性开发的途径、并行处理系统的结构和多机系统的耦合度
> - 计算机系统的分类方法（弗林分类法）
>
> 翻译、解释、计算机系统结构、透明性 、软件兼容、模拟、 仿真、并行性、系列机、兼容机、时间重叠、紧耦合系统

## *存储程序与计算机组成

计算机由==运算器、存储器、控制器、输入设备和输出设备==五大基本部件组成

==存储程序==的基本含义：将编好的程序和原始数据事先存入存储器中，然后再启动计算机工作

计算机系统=硬件系统+软件系统/固件

### 多级层次结构

现代计算机系统可以看成按功能划分的多级层次结构，如图：

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303031821854.png" alt="image-20230303182157799" style="zoom:50%;" />

通常第1, 2级是由解释的方法实现的；更高级由翻译的方法实现

虚拟机器是指以软件或以软件为主实现的机器

## *计算机系统结构、组成和实现

- ==计算机系统结构==是**程序员（机器语言）所看到的计算机的属性**，一般包括：数据表示、寻址方式、寄存器组织、指令系统、存储系统组织、中断机构、管态和用户态的定义和切换、机器级I/O结构、信息保护方式和保护机构
- ==计算机组成==是指计算机系统结构的==逻辑实现==，包括：机器级内部的==数据流==、==控制流==的组成和逻辑设计等
- ==计算机实现==是指计算机组成的==物理实现==，着眼于器件技术和微组装技术

要注意，计算机的组成与实现属于计算机系统的内特性，这些特性对于程序员是==透明==的，即程序员的视角看似乎不存在

同一系统结构可能有多种组成；一种组成可能有多种不同实现

> 可能会有要去区分系统结构和计算机组成的题目，例如：
>
> 指令系统的确定属于系统结构；而指令的实现属于计算机组成；**主存地址寄存器**也属于计算机组成
>
> 区分的关键在于对于程序员是否可见；如果不可见再看他是不是物理的实现

## 设计思路

### 软硬件取舍基本原则

1. 性价比：在现有硬件和器件条件下，系统要有高的性价比
2. 组成合理：组成技术要合理
3. 软硬结合：实现时要注意“软硬结合”

### 基本设计思路

1. 由上向下：从应用开始逐级往下，适合专用机的设计
2. 由下向上：可设计通用计算机，但容易软硬脱节
3. ==从中间开始==：中间一般是指传统机器级与操作系统级之间

## 计算机设计量化准则

### 性能指标

1. 机器字长：参与运算的数的基本位数
2. 数据通路宽度：数据总线一次所能并行传送信息的位数
3. 主存容量：主存储器所能存储的全部信息量
   - 对于字节编址的机器，一般直接用字节数表示
   - 对于字编址的机器，一般用字数x字长表示

### 定量原理

#### *Amdahl定律

==系统中对某一部件采用某种更快的执行方式所能获得的系统性能改进程度==

- 可改进比例$\large Fe=\frac{可改进部分占用的时间}{改进前整个任务的占用时间} < 1$
- 性能提高比$\large Se=\frac{改进前改进部分的执行时间}{改进后改进部分的执行时间} > 1$
- 改进前任务执行时间$T_0$
- 改进后任务执行时间$T_n$

$$
加速比S_n=\frac{T_0}{T_n}=\frac{1}{(1-Fe)+\frac{Fe}{Se}}
$$

#### *CPU性能公式

- 设程序执行过程中处理的指令数为$IC$
- 指令时钟数$\large CPI=\frac{CPU时钟周期数}{IC}$，即多少个时钟周期能执行一个指令
- 如果计算机系统有$n$种指令，其中第$i$种的时钟数为$CPI_i$，在程序中第$i$中指令出现的次数为$I_i$，则有：$\large CPI=\sum\limits_{i=1}^n(CPI_i\times\frac{I_i}{IC})$
- $\large IPC=\frac{1}{CPI}$

$$
CPU执行时间=\frac{CPU时钟周期数}{时钟频率}=\frac{指令数\times CPI}{时钟频率}
$$

### 计算机系统性能标准

- 吞吐量：系统在单位时间内处理请求的数量
- 响应时间：系统对请求作出响应的时间

#### *运算速度

- 每秒执行百万指令$\large MIPS=\frac{指令条数}{执行时间\times10^6}=\frac{主频}{CPI\times10^6}$
- 每秒百万次浮点运算$\large MFLOPS=\frac{浮点操作次数}{执行时间\times10^6}$

#### *等效指令速度

因为不同指令所需的执行时间有较大差异，所以通过统计各类指令在程序中所占比例进行折算

设$W_i$为指令使用频度，$i$为指令种类：

- 等效指令执行时间$\large T=\sum\limits^n_{i=1}(W_i\times T_i)$
- 等效指令速度$\large MIPS=1/\sum\limits^n_{i=1}\frac{W_i}{MIPS_i}$
- 等效$\large CPI=\sum\limits^n_{i=1}(CPI_i\times W_i)$

### 性能比较

- 平均执行时间$\large S_m=\frac{1}{n}\sum\limits^n_{i=1}T_i$
- 加权执行时间$\large A_m=\sum\limits^n_{i=1}(W_i\times T_i)$
- 归一化执行时间，一般标识为几何平均速度，其与机器无关，与程序的执行时间无关，可以平滑掉样本之间的倍数差异

### 性能评价

使用评测程序(Benchmark)来评价计算机系统性能

## 系统结构影响因素

### *软件可移植性

为了节约时间、经济成本，在新的系统中必须要解决软件的可移植性问题，有以下办法：

1. 采用统一的==高级语言==

2. 采用==系列机==，即**同一厂家**生产的具有**相同的系统结构**，不同组成和实现的一系列计算机系统

   兼容机是**不同厂家**生产的具有**相同的系统结构**的计算机系统

   系列机与兼容机的区别在于是否是同一厂家生产

   **向后兼容**最重要

3. 采用==模拟==和==仿真==，在一台现有的计算机上实现另一台计算机的指令系统
   - 模拟：指用==**软件**==的方法在一台现有的计算机A上实现另一台计算机B的指令系统
   - 仿真：指用一台现有计算机A上的**微程序去解释**实现另一台计算机B的指令系统
   - 模拟和仿真的区别在于**模拟使用机器语言解释**，**仿真使用微程序解释**
   - 模拟慢，仿真快；模拟在主存中，仿真在控存中；差别大的机器很难用仿真实现

### 器件

### 应用

## 并行性

### 概念

#### *并行性含义

并行性包含以下二重含义：

- ==同时性==：两个或多个事件在同一**时刻**发生
- ==并发性==：两个或多个事件在同一**时间间隔内**发生

#### 并行性等级

从**数据**处理的并行性来看，由低到高可以分为：

- 位串字串
- 位并字串
- 位片并字串
- 全并行

从**信息加工**的角度看，又可分为：

- 存储器操作并行：如一个存储周期内访问多个字
- 处理器操作步骤并行：流水线处理机
- 处理器操作并行：阵列处理机
- 指令、任务、作业并行： 多处理机

#### *并行开发途径

1. ==时间重叠==：在并行性概念中引入时间因素，让多个处理过程在**时间上相互错**开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周期而赢得速度。流水线处理机常使用这种方法
2. ==资源重复==：在并行性概念中引入空间因素，通过重复设置硬件资源来提高可靠性或性能。阵列处理机会通过资源重复，设置大量算数逻辑单元，以实现空间上的并行
3. ==资源共享==：利用软件的方法让多个用户**按一定时间顺序轮流**地使用同一套资源，以提高利用率，这样也可以提高整个系统的性能。多处理机主要采用这种方法

#### 耦合度

耦合度：反映多机系统中各机器之间物理连接的紧密程度和交叉作用能力的强弱

可以分为：

- 最低耦合，各计算机之间无物理连接，如**脱机处理系统**
- 松散耦合，多台计算机通过通道或通信线路实现互联，如**外设**
- 紧密耦合，多台计算机通过总线或高速开关互联

## 计算机的分类

### Flynn分类法

按照**指令流和数据流的多倍性特征**对计算机系统进行分类

- 单指令流单数据流SISD：每次只译码一条指令，并操作一个数据

  一般的单处理机

- 单指令流多数据流SIMD：一条指令操作多数据

  阵列机、并行处理机、向量处理机

- 多指令流单数据流MISD：多条指令并行处理同一数据

  超标量，超长指令字计算机

- 多指令流多数据流MIMD：能实现作业、任务、指令各级全面并行的系统

  



# Chapter 2 数据表示和指令系统

## 数据表示

> 传统机器数据表示：
>
> - 传统机器数据表示：
>   - 定点数：原码、反码、补码、移码
>   - 浮点数：尾数、基数和阶码。IEEE754 标准
>   - 字符：常用ASCII码
>   - 汉字：输入码，汉字内码，汉字字模码
> - 高级数据表示：自定义的数据表示，向量数据表示、堆栈数据表示
> - 数据校验原理：奇偶校验码

### 数据表示和数据结构

- ==数据表示==是指计算机**硬件**能够直接识别和引用的数据类型
- ==数据结构==反映面向**应用**所要用到的各种数据元素或信息单元之间的结构关系

数据表示和数据结构都是==数据类型==的子集

### 无符号数

字长$n+1$位，则无符号数的表示范围为$[0,2^{n+1}-1]$

> 后面若无特殊说明，则字长默认为$n+1$位

### 有符号数

- 原码：最高位为符号位，其余位为绝对值，取值范围为$[1-2^n,2^n-1]$
- 反码：正数时与原码一样，负数时为除符号位按位取反
- 补码：正数时与原码一样，负数时为除符号位取反后再加1，取值范围$[-2^n,2^n-1]$

在原码和反码中，真值0都有两种不同的表示形式；但在补码中只有一种，这使得补码可以表示的负数比正数多一个

对于一个负数补码数，其值就等于除符号位所表示的值减去$2^n$。如1011除符号位表示的值为3，那么其补码值为$3-8=-5$

### 定点数

小数点的位置固定在最高有效数位之前，符号位之后，所以是纯小数。表示范围（机器字长为$n+1$）：

- 原码/反码定点小数：$[2^{-n}-1,1-2^{-n}]$

- 补码定点小数：$[-1,1-2^{-n}]$ (补码表示为100...时取值为-1)

### *浮点数

#### 浮点数表示

用$V=M\times2^E$表示一个浮点数：

- 尾数$M$为纯小数，可以用原码或补码表示
- 阶码$E$是给浮点数指定$2^E$权重，可以用补码或移码表示

![image-20230621223342182](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306212233399.png)

#### 浮点数的规格化

一个规格化的浮点数，其尾数用**补码**表示时，其尾数的**第一位和第二位必须不同**，即为1.0xxxx或0.1xxx形式，这样保证值在(0.5,1)和(-1,-0.5)

若阶码和尾数都用设阶码为$k+1$位，尾数为$n+1$位，浮点数典型值如下：

|                        |  阶码   |  尾数   |              真值               |
| :--------------------: | :-----: | :-----: | :-----------------------------: |
|        最大正数        | 011...1 | 011...1 |      $(1-2^{-n})2^{2^k-1}$      |
|     绝对值最大负数     | 011...1 | 100...0 |          $-2^{2^k-1}$           |
|        最小正数        | 100...0 | 00...01 |         $2^{-(n+2^k)}$          |
|    规格化的最小正数    | 100...0 | 010...0 |          $2^{-2^k-1}$           |
|     绝对值最小负数     | 100...0 | 111...1 |          $-2^{-n-2^k}$          |
| 规格化的绝对值最小负数 | 100...0 | 101...1 | $-(\frac{1}{2}+2^{-n})2^{-2^k}$ |

#### 阶码的移码表示

移码表示的阶码，最终的阶码值E要减去一个Bias，这个Bias的取值在IEEE单精度中为127，双精度为1023

若阶码采用移码表示，则有以下特点：

- 浮点数的最高位代表浮点数的正负
- 移码全为0时，对应真值最小；移码全为1时，对应真值最大
- 阶码越大，则浮点数越大

#### IEEE浮点数

默认采用移码表示，尾数为补码且取值范围为[1.0-2)，由于首位总是1，所以将其省略。若尾数值为1.101，则尾数只需表示0.101即可

将浮点数的位表示划分为三个字段，分别对这些值进行编码：

| 1位  |        k位         |        n位         |
| :--: | :----------------: | :----------------: |
| $s$  | $e_{k-1}...e_1e_0$ | $f_{n-1}...f_1f_0$ |

- 最高位是一个单独的符号位$s$编码符号
- $k$位的阶码字段$exp=e_{k-1}...e_1e_0$编码阶码$E$
- $n$位小数字段$frac=f_{n-1}...f_1f_0$编码M

|          | s    | exp  | frac |
| -------- | ---- | ---- | ---- |
| 单精度   | 1    | 8    | 23   |
| 双精度   | 1    | 11   | 52   |
| 扩展精度 | 1    | 15   | 64   |

>IEEE example(from https://www.geeksforgeeks.org/ieee-standard-754-floating-point-numbers/):
>```
>85.125
>85 = 1010101
>0.125 = 001
>85.125 = 1010101.001
>       =1.010101001 x 2^6 
>sign = 0 
>
>1. Single precision:
>biased exponent 127+6=133
>133 = 10000101
>Normalised mantisa = 010101001
>we will add 0's to complete the 23 bits
>
>The IEEE 754 Single precision is:
>= 0 10000101 01010100100000000000000
>This can be written in hexadecimal form 42AA4000
>
>2. Double precision:
>biased exponent 1023+6=1029
>1029 = 10000000101
>Normalised mantisa = 010101001
>we will add 0's to complete the 52 bits
>
>The IEEE 754 Double precision is:
>= 0 10000000101 0101010010000000000000000000000000000000000000000000
>This can be written in hexadecimal form 4055480000000000 
>```

### 汉字表示

- 汉字输入码：包括数字码、拼音码、字形码，用于输入汉字
- 汉字机内码：通过不同输入码输入的汉字，其在计算机内部的表示是唯一的
- 汉字字模码：用于汉字在计算机上的显示

$$
汉字机内码=汉字国标码+8080H=区位码+A0A0H
$$

### 高级数据表示

引入一些高级数据表示，有时有利于机器的计算。有以下几种高级数据表示：

- 自定义数据表示
- 向量数据表示
- 堆栈数据表示

#### 自定义数据表示

在高级语言中，运算符不反映参与计算的数据类型，比如两个int类型的变量或者两个double类型的变量之间都可以用+进行加法运算；但是机器语言程序中的指令要用==操作码==指明操作数的类型，比如两个整形数的加法和两个浮点数的加法是完全不同的指令

如上所述的情况给高级语言到机器语言的编译带来了非常大的不方便，为了解决这个问题，引入两种解决方法：

##### 1.带标志符的数据表示

让**每个数据都带有类型标志**，将数据类型与数据本身直接联系在一起，使机器语言中的操作码与高级语言中的运算符一致。标志符由编译器或其他系统软件建立，对程序员透明

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303052020797.png" alt="image-20230305202029737" style="zoom:50%;" />

优点：

- 提高了操作码的通用性，简化了指令系统和程序设计
- 简化了指令系统和程序设计
- 便于实现一致性检查，可由硬件直接快速地检测出多种程序错误
- 能够由硬件自动完成数据类型转换
- 支持了数据库系统的实现与数据类型无关的要求
- 为软件调试和开发提供了支持

缺点：

- 每个数据字因增设标志符，可能会使程序所占用的主存空间增加
- 采用标志符会降低指令的执行速度，以换取程序的设计时间、编译时间和调试时间缩短
- 数据和指令的长度可能不一致
- 硬件复杂度增加

##### 2.数据描述符

对于**向量、数组、记录**等多维或结构复杂的数据，由于每个元素*具有相同属性*，没有必要让每个数据都带标志符，而是将它们的属性组织为==描述符==，与数据**分开存放**

因为描述符与数据分开，所以在访问数据时要先访问描述符寄存器，也就多一层寻址

优点：

- 将描述符按树形连接可以描述多维数组
- 为向量、数组等数据结构的实现提供了一定的支持

#### 向量数据表示

为实现向量、数组数据结构的快速运算，可以增设向量数据表示

比如原来需要用很多加法指令实现的向量加法，在引入向量数据表示后可用一条指令完成：

![image-20230305203451604](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303052034638.png)

可以快速形成元素地址，实现数据块的预取

#### 堆栈数据表示

堆栈有两种类型：

1. 寄存器堆栈：用一组专门的寄存器构成，又称为**硬堆栈**

   栈顶固定，各寄存器相互连接，自动推移（联想80386汇编中的浮点数寄存器）

2. 存储器堆栈：从主存中划出一段区域来作堆栈，这种堆栈又称为**软堆栈**

   栈底固定，栈顶浮动，所以需要一个专门的硬件寄存器作为栈顶指针

具有堆栈数据表示的机器称为堆栈机器

### 确定数据表示

应坚持以下原则：

1. 缩短程序的运行时间
2. 减少CPU与主存之间的通信量
3. 通用性和利用率要高



### 数据校验原理

数据校验码：能够发现错误或能够自动纠正错误的数据编码

编码最小距离：任意两组合法代码之间二进制位数的最少差异
$$
L-1=D+C(D\ge C)
$$
其中$L$是编码最小距离；$D$是检错的位数；$C$是纠错的位数

#### 奇偶校验

可以检测出一位（或奇数位）错误，奇偶校验码的码距等于2

- 奇校验：整个校验码（包含有效信息位和校验位）中1的个数为奇数
- 偶校验：整个校验码中1的个数为偶数

#### 交叉奇偶校验

不仅每一个字节有一个奇偶校验位做==横向校验==，而且全部字节的同一位也设置一个奇偶校验位 做==纵向校验==

交叉校验可以发现两位同时出错的情况



## 数据计算

1. 串行、并行加法器、溢出判断与检测、移位操作
2. 乘法电路基本结构：BOOTH乘法器（1位）
3. 除法电路基本结构：加减交替除法器（补码）
4. 逻辑运算：与、或、非、异或运算
5. 运算器基本结构

### 加法运算

#### 全加器

全加器结构如图：<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303061649085.png" alt="image-20230306164959025" style="zoom:50%;" />
$$
S_i= A_i\oplus B_i\oplus C_{i-1}=P_i\oplus C_{i-1}\\
C_i=A_iB_i+(A_i\oplus B_i)C_{i-1}=G_i+P_iC_{i-1}\\
G_i=A_iB_i\\
P_i=A_i\oplus B_i
$$

其中，进位产生函数用$G_i$表示，进位传递函数用$P_i$表示

- 串行加法器：只有**1个全加器**，数据逐位串行送入加法器进行运算
- 并行加法器：由**多个全加器**构成，位数的多少取决于机器的字长

#### 并行加法器

并行加法器又能细分为两种：

1. n位行波进位加法器：全加器的简单堆叠<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306220937827.png" alt="image-20230622093703618" style="zoom: 25%;" />
2. 超前进位加法器（BCLA）：每个进位都不需要等待低位，直接计算可以得到

n位行波进位加法器虽然结构简单，但是有个致命的缺点：随着全加器的堆叠，全加器的==延迟也叠加==了，每个全加器都要等待前一个全加器的计算结果。若生成每一级进位的延迟为$2ty$，那么$n$位的延迟则为$2nty$

为了解决这一问题，可以使用超前进位加法器，他与前者的区别是他用更复杂的逻辑表达来直接计算结果的每一位。这样确实大大降低了延迟，但是如果加法位数多，那么高位进位的逻辑表达式将相当复杂，这也会使得全加器的设计变得非常棘手。为解决这一问题，引入了==先行进位==方式：

1. 单级先行进位方式：组内并行，组间**串行**

   比如16位加法器可以分为4组，每组实现4位超前进位加法器，之后串行得到16位加法器。这样的加法器相对串行加法器仅有4倍延迟

2. 多级先行进位方式：组内并行，组间**并行**

   如下面的多级先行进位加法器：第一个周期计算出来所有的G和P和最低4位的加法结果；第二个周期使用G和P计算出所有的进位C，包括$C_4,C_8,C_{{12}}$；最后一个周期用所有的进位C和输入计算得到最终的结果
   
   <img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306220938722.png" alt="image-20230622093845550" style="zoom:33%;" />

#### 定点数运算

有以下规则：

- 操作数以补码表示
- 符号位也参与运算
- 做加法则两数直接相加；做减法则与减数的==机器负数==相加
- 运算结果用补码表示

>机器负数：连同符号位的所有位取反，末尾加1

#### 溢出判断

设操作数为$X$和$Y$，进位为$C$，计算结果为$S$

1. 一个符号位判断：$\overline X_s\overline Y_sS_s+X_sY_s\overline S_s$

2. 进位位判断：$C_s\oplus C_1$

3. ==变形补码==判断：$S_{s1}\oplus S_{s2}$

   $S_{s1}$是原来的符号位，$S_{s2}$是计算时扩充的符号位，对于$X$来说$X_{s1}=X_{s2}$，就是把原来的符号位再复制一位。若$S_{s1}S_{s2}$为00或11，则无溢出；01为正溢，10为负溢



### 乘法运算

补码一位乘法——Booth乘法

寄存器占用：

- A寄存器：部分积与最后乘积的高位部分，初值为0
- B寄存器：被乘数X
- C寄存器：乘数Y，运算后C寄存器中不再需要保留乘数，改为存放乘积的低位部分

乘法步骤：

1. **符号位参与运算**

2. 乘数Y最低位后面增加一位附加位$Y_{n+1}$，初值为0

3. 由于每求一次部分积要右移一位，所以乘数的最低两位$Yn$、$Yn+1$的值决定了每次应执行的操作:

   | 判断位$Y_nY_{n+1}$ |             操作             |
   | :----------------: | :--------------------------: |
   |        0 0         |    原部分积加0；右移一位     |
   |        0 1         | 原部分积==加$X$==；右移一位  |
   |        1 0         | 原部分积==加$-X$==；右移一位 |
   |        1 1         |    原部分积加0；右移一位     |

4. 移位按==补码右移==规则进行，共需做$n+1$次累加，$n$次移位（把首位移到原来的末位就不再移位了）

> <img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306081904910.png" alt="image-20230608190427692" style="zoom:33%;" />



### 除法运算

加减法交替除法：

第一次操作：

| $[X]_补$与$[Y]_补$ |       操作       |
| :----------------: | :--------------: |
|        同号        | $[X]_补+[-Y]_补$ |
|        异号        | $[X]_补+[Y]_补$  |

| $[r_i]_补$与$[Y]_补$ | 上商 |    求新余数的操作     |
| :------------------: | :--: | :-------------------: |
|         同号         |  1   | 左移一位；加$[-Y]_补$ |
|         异号         |  0   | 左移一位；加$[Y]_补$  |

一共左移$n$次，第一次得到的商移位到最左侧即停止，商的末位恒置1

寄存器使用情况：

- A寄存器：存放被除数X，不断变化最后为余数
- B寄存器：存放除数Y
- C寄存器：存放商Q，它的初值为0

><img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306081905945.png" alt="image-20230608190506760" style="zoom: 33%;" />



### 浮点运算

以下浮点运算默认语境为阶码和尾数都用补码表示

#### 浮点加减

1. 对阶：先求阶差，然后小阶向大阶看齐，小阶尾数每右移一位，阶码+1
2. 尾数加减：若尾数用双补码表示，计算得到结果可能有6种，之后要根据不同的情况进行规格化或溢出判断

| 00.1xxx  | 11.0xxx  | 00.0xxx  | 11.1xxx  | 10.xxxx  | 01.xxxx  |
| :------: | :------: | :------: | :------: | :------: | :------: |
| 已规格化 | 已规格化 | 进行左规 | 进行左规 | 进行右规 | 进行右规 |

- 左规：尾数每左移1位，阶码-1；一直左规，直至成为规格化数为止
- 右规：尾数右移1位，阶码+1；右规仅进行这一次

之后判断是否溢出：

- 若阶码为01.xxx，此时发生上溢，需做溢出中断处理
- 若阶码为10.xxx，此时发生下溢，不做溢出处理，认为该数为机器0

#### 浮点乘法

1. 阶码相加
2. 尾数相乘
3. 尾数结果规格化（可能需要一次左规）

#### 浮点除法

1. 尾数调整：若$|M_A|\ge|M_B|$，则$M_A$需要右移一位，阶码+1
2. 阶码相减
3. 尾数相除

### 逻辑运算

逻辑非、逻辑乘、逻辑加、按位异或

### 运算器

运算器的组成为：

1. 实现基本算数、逻辑运算功能的ALU
2. 提供操作数与暂存结果的寄存器组
3. 判别逻辑和控制电路

## 指令系统

### 寻址技术

寻址技术：寻找操作数及其他信息的地址的技术

主要研究三个方面的内容：编址方式、寻址方式和定位方式

#### 编址单位与编址方式

编址有不同的单位：字、字节、位、块等

##### 编址单位

- ==字编址==：编址单位=访问单位

- ==字节编址==：为了适应非数值计算而产生，编址单位 ＜ 访问单位

字节编址引入了字节顺序问题，对应的解决方案是大端法和==小端法==；小端模式地址转换方便，容易进行高精度的运算

字节编址还引入了对齐问题，一般采取==边界对齐==

##### 编址方式

- ==分类编址==：将部件适当分类，通用寄存器、主存和IO每类各自从“0”开始编址

- 统一编址：把各种部件统一编成一个从0开始的一维线性空间

- 隐含编址：采用事先约定的编址方式寻址，比如堆栈、专用寄存器和Cache常采用这种方法，这样不需要进行地址计算

#### 寻址方式

寻址方式：指令寻找到所需数据的方法

- 显式寻址：在指令中设置专门的寻址方式字段，用二进制代码来表明寻址方式类型
- 隐式寻址：由指令的操作码字段说明指令格式并隐含约定寻址方式

立即数寻址、寄存器寻址、主存储器寻址、堆栈寻址。其中主存寻址包括直接、间接或变址寻址

![image-20230622143329309](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221433527.png)![image-20230622143352043](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221433233.png)

![image-20230622143417293](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221434476.png)

![image-20230622143437685](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221434873.png)

![image-20230622143452401](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221434589.png)

##### 间址vs变址

间接寻址和变址寻址都是为了解决操作数地址的修改问题，都能做到不改变程序而修改操作地址

|              | 间址寻址 |  变址寻址  |
| :----------: | :------: | :--------: |
|   地址位置   |   主存   | 基址寄存器 |
|    偏移量    |    无    |     有     |
|    优缺点    | 容易但慢 |  麻烦但快  |
| 对数组的支持 |    差    |     好     |

#### 定位方式

- 逻辑地址：程序员编写程序时所使用的地址
- 物理地址：程序在主存中的实际地址

因为逻辑地址空间和物理空间是不一致的，所以需要进行逻辑地址到实际地址的转换。有三种定位方法：

- 直接定位：在程序**装入主存之前**，物理地址就已确定，很少用
- 静态重定向：程序**装入主存的过程中**进行地址变换
- 动态重定向：程序**执行**的过程中进行地址变换

### 指令格式及优化

一条指令由==操作码==和==地址码==构成

指令格式的设计有两个主要目标：

- 节省程序的**存储空间**
- 指令格式尽量规整，便于**译码**

为了达成这两个目标，我们主要研究操作码和地址码的优化表示

#### 操作码

指令操作码可以按编码方式分为两类：

- 规整型：定长编码
- 非规整型：变长编码，如==扩展操作码==：操作数地址多的指令操作码短，操作数地址少的操作码长

#### 操作码优化

在足够表达所有指令的前提下，使操作码占用的位数最少

1. ==Huffman编码==

依托于Huffman树，回看数据结构，这里只给出一些数学相关：

信息源熵（最短平均长度）：
$$
H=-\sum\limits^n_{i=1}p_i·\log_2p_i
$$
其中，$p_i$为指令$I_i$的使用频度

信息冗余量：
$$
R=1-\frac{H}{实际平均码长}
$$
采用Huffman编码的实际平均码长最短，但是具体码值不唯一，操作码长度不规则，并且难以组成定长的指令

在构建Huffman树的时候，要注意**短码不能是长码的前缀**

Huffman树虽然信息冗余量是所有编码方式中最低的，但是编码不规整，译码不方便

2. ==扩展编码==

有以下特点：

- 操作码长度不固定，但只有有限的几种长度
- 使用频度高的指令用短操作码表示，使用频度低的指令用长操作码表示(哈夫曼压缩思想)

比如2-4扩展编码就是将概率高的用2位表示，概率低的用4位表示

#### 地址码优化

我们希望寻址范围大，但还不想要地址码长度太宽，就要想想办法——==变长地址码==：对于操作码不同长度的指令可以采用多种地址长度

#### 优化总结

1. 选择合适的编码方式**缩短操作码的平均码长**
2. 采用多种寻址方式来**缩短地址码长度**
3. 采用多种地址制增强指令功能，**缩短程序长度**
4. 在同种地址制内采用**多种地址形式**，让长操作码与短操作码组配
5. 使用多种**不同的指令长度**

### 指令系统的发展

#### CISC&RISC

现有的指令集有两个大类，分别是CISC和RISC

- CISC：进一步**增强原有指令的功能**以及设置更为**复杂**的新指令取代原先由软件子程序完成的功能，实现软件功能的硬化
  - 指令数量多且指令长度不固定，指令格式和寻址方式多样
  - 一些指令涉及存储器读写
  - 采用微程序控制
- RISC：通过**减少指令种类**和**简化**指令功能来降低硬件设计的复杂度，提高指令的执行速度
  - 指令数量少且指令长度固定
  - 大部分采用RR寻址
  - 采用组合逻辑控制

#### RISC的设计原则

指令系统只使用频度高的指令（加上少量其他有用的指令）；大多数指令在单周期内完成；LOAD/STORE结构；硬布线控制逻辑，以提高指令执行速度；减少指令和寻址方式的种类；注重编译优化技术

#### 指令系统的设计方向

CISC设计方向：增强指令功能；设置功能复杂的指令面向目标代码、高级语言和操作系统；用一条指令代替一串指令

RISC设计方向：只保留功能简单的指令；功能较复杂的指令用子程序来实现；减少CPI

RISC的精华就是==减少CPI==

#### 设计RISC的关键技术

1. ==重叠寄存器窗口==：可以减少大量主存访问操作

   设置一个数量比较大的寄存器堆，并把它划分给很多个窗口。在每个过程使用的几个窗口中有一个窗口是与前一个过程共用，还有个窗口是与下一个过程共用

2. ==延迟转移==：使指令流水线不断流

   在转移指令之后插入一条没有数据相关的有效的指令，而转移指令被延迟执行，这种技术称为延迟转移技术；指令序列的调整由编译器进行

3. ==指令取消==：延迟转移技术在很多情况下找不到可以用于调整的指令，所以有些RISC采用指令取消技术，分为三种情况：

   - 向后转移（循环程序）
   - 向前转移（if-then）
   - 隐含转移
   
4. ==指令流调整==：通过变量重新命名消除数据相关，提高流水线执行效率





# Chapter 3 存储器层次结构

## 存储系统概念和层次化结构

为了解决存储容量、存取速度和价格之间的矛盾，我们一般将不同的存储器按一定体系结构组织起来

### 局部性原理

- 时间局部性：最近访问的存储单元在不久的将来仍将被访问
- 空间局部性：下次访问的存储单元很可能在最近访问的存储单元附近

## 主存储器的组织和控制

主存储器是整个存储系统的核心，它用来存放计算机运行期间所需要的程序和数据，CPU可直接随机地对它进行访问。主存由**存储体、地址译码和驱动电路、I/O和读写电路**等构成：

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303270951554.png" alt="image-20230327095151482" style="zoom: 33%;" />

### 技术指标

#### 存储容量

存储容量是指主存所能容纳的二进制信息总量

> 假设某计算机容量为$64K\times16$，表示他有$64K$个字，每个字的字长为16位

#### 存取速度

1. 存取时间$T_a$：从启动一次存储器到完成该操作所经历的时间
2. 存取周期$T_m$：进行一次完整的读写操作所需的全部时间，即连续两次访问存储器操作之间所需要的最短时间

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271016999.png" alt="image-20230327101625925" style="zoom:50%;" />

#### 主存带宽

表示每秒从主存进出信息的最大数量
$$
B_m=主存等效工作频率\times主存位宽\div8 \\
=内存时钟频率\times倍增系数\times主存位数\div8
$$

>以DDR400内存为例，它的运行频率为200MHz，数据总线位数为 64bit，由于上升沿和下降沿都传输数据，因此倍增系数为2
>
>此时带宽为： $200×2×64/8＝3.2GB/s$

### 主存分类

主存储器通常分为RAM和ROM两大部分：RAM可读可写，ROM只能读不能写

#### RAM

- SRAM：存储电路以==双稳态触发器==为基础，常用作Cache
- DRAM：存储电路以==电容==为基础，常用作主存

#### *DRAM的刷新

DRAM为了维持MOS型动态记忆单元的存储信息，每隔一定时间必须对存储体中的所有记忆单元的栅极电容补充电荷，这个过程就是==刷新==

刷新==按行定时进行==，常见的刷新方式包括：==集中式==、==分散式==和==异步式==

1. 集中式：在允许的**最大刷新间隔内**，按照存储芯片容量的大小几种安排若干个刷新周期，刷新时停止读写操作，有$刷新时间=存储体矩阵行数\times刷新周期=行数\times存取周期$。但是集中式会让CPU连续等待一段较长的时间

   <img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221454188.png" alt="image-20230622145429965" style="zoom: 33%;" />

2. 分散式：分散刷新是指把刷新操作分散到每个存取周期内进行，一个系统存取周期内刷新存储矩阵中的一行。这样做没有死区，但是大大降低了整机速度（存取周期翻倍）

   <img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221454169.png" alt="image-20230622145444965" style="zoom:50%;" />

3. 异步式：刷新操作平均分配到整个最大刷新间隔时间内进行。$相邻两行刷新间隔=最大刷新间隔\div行数$

   <img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306221455146.png" alt="image-20230622145525941" style="zoom:33%;" />

最大刷新间隔默认取2ms

注意：因为所有芯片同时被刷新，所以在考虑刷新问题时，应当从==单个芯片==的存储容量着手

#### ROM

ROM具有非易失性，即使断电ROM中存储的信息也不会消失

### *主存设计

要解决三个问题：芯片的选用、片内地址分配与片选逻辑、信号线的连接

#### 扩展

- ==位扩展==：在位数方向扩展，即**加大字长**。连接方式是将各存储芯片的地址线、片选线和读/写线相应地并联起来，而将各芯片的数据线单独列出

  如8个$64K\times1$的SRAM芯片组成$64K\times8$的存储器：

  ![image-20230327130000532](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271300621.png)

- ==字扩展==：仅在字数方向扩展，而位数不变。字扩展将芯片的地址线、 数据线、读/写线并联，由片选信号来区分各个芯片

  如用4个$16K\times8$的SRAM组成$64K\times8$的存储器：![image-20230327130101948](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271301040.png)

一般来说为了构成一个容量较大的存储器，位扩展和字扩展方法都会使用到，如$16K\times4$组成$64K\times8$的存储器：

![image-20230327165424776](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271654896.png)



#### 地址译码方式

通常采用双译码方式：把$K$位地址码分成接近相等的两段，一段用于水平方向用作$X$地址线，供$X$地址线译码；另一段用于竖直方向用作$Y$地址线，供$Y$地址译码器译码

#### 片选

片选要做的事情就是把地址线送来的地址信号翻译成对应存储单元的选择信号，

##### 线选法

用除片内寻址外的**高位地址线**直接分别接至各个存储芯片的片选端，当某地址线信息为0时，就选中对应的存储芯片，比如一个由4个$2k\times8$芯片构成的$8k\times8$的存储器：

| 芯片 | $A_{14}～A_{11}$ | $A_{10}～A_0$ |  地址范围   |
| :--: | :--------------: | :-----------: | :---------: |
| 0号  |       1110       | 00...0~11...1 | 7000~77FF H |
| 1号  |       1101       | 00...0~11...1 | 6800~6FFF H |
| 2号  |       1011       | 00...0~11...1 | 5800~5FFF H |
| 3号  |       0111       | 00...0~11...1 | 3800~3FFFH  |

##### 全译码法

全译码法将片内寻址外的全部高位地址线作为地址译码器的输入，把经译码器译码后的输出作为各芯片的片选信号，将它们分别接到存储芯片的片选端，以实现对存储芯片的选择。如：

| 芯片 | $A_{12}～A_{11}$ | $A_{10}～A_0$ |  地址范围   |
| :--: | :--------------: | :-----------: | :---------: |
| 0号  |        00        | 00...0~11...1 | 0000~07FF H |
| 1号  |        01        | 00...0~11...1 | 0800~0FFF H |
| 2号  |        10        | 00...0~11...1 | 1000~17FF H |
| 3号  |        11        | 00...0~11...1 | 1800~1FFFH  |

使用全译码法，每片芯片的地址范围是**唯一确定的而且是连续的**，便于扩展

> 如何判断地址覆盖？
>
> 以上面的全译码法举例：若地址线位数有20位，但是只用到了13位，那就出现地址覆盖；若地址线位数也恰好是13位，那么就没有地址覆盖

## Cache

高速计算机的性能通常受到主存带宽和响应时间的限制：

- 响应时间：一次访存所需要的时间
- 带宽：单位时间内的访存次数

而因为cpu的发展速度远快于DRAM的发展速度，带来了“CPU-主存瓶颈”；为解决这一问题，就在CPU和主存之间添加Cache：

![image-20230327103936434](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271039506.png)

### Cache的基本结构

访问主存时，先访问Cache：

- 若命中，则直接访问Cache
- 若不命中，则访问主存，将字送往CPU，并把包括该字在内的一整块都装入Cache

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303271042447.png" alt="image-20230327104256413" style="zoom:50%;" />

### 地址的映像与变换

- 地址映像：把存放在主存中的程序按照某种规则装入到Cache中，并建立主存地址与Cache地址之间的**对应关系**
- 地址变换：当程序已经装入到Cache之后，在实际运行过程中，把主存地址变换成Cache地址

为了方便地址映像和变化，就把Cache和主存都划分为**相同大小的块**，这样映像问题就变成了对应问题，有多种对应的方法

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306060917060.png" alt="image-20230606091734884" style="zoom:50%;" />

#### 全相联映像

主存中的任意一块都可以映像到Cache中的==任意==一块

实现复杂，很少采用

#### 直接映像

主存中的每一块只能装入到Cache内==唯一==一块位置：$Cache块号=主存区内块号~mod~Cache总块数$

使用直接映像，那么整个Cache地址和主存地址的**低位部分完全相同**。比如若Cache一共有16块，那么cache块号与主存块号的低4位就会完全一样，这样使得映射非常简单；1块Cache会映射$主存块数\div Cache块数$的主存块

显然，因为多个主存块会映射到一个Cache块，那么需要一个区号表来存储该Cache块存储的到底是哪个主存块；除此以外还需要一个有效位来标识该块的内容是否有效（决定是否移进或替换）：

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306060928650.png" alt="image-20230606092856498" style="zoom:50%;" />

#### 组相联映像

- **主存块到Cache组set之间采用直接映像**方式，即一个主存块只能映像到一个Cache组内
- **对应的组内采用全相联映像**方式，即一个主存块可以放入指定Cache组内任何1个块位置
- 组内$N$块的组相联映像称为$N$路组相连

$Cache组号 = 主存区内块号~mod~组数$，也就是说主存块号的低几位就是Cache的组号

到这里，我们解决了一个主存块放在哪个Cache组里的问题；但还需要解决如何知道一个主存块在组里哪个位置的问题——使用主存块的tag与cache中的块一一比较

地址变换时：首先根据组号查到对应cache组的目录表，然后在目录表内查区号（tag）

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306061007527.png" alt="image-20230606100754337" style="zoom:50%;" />

### 替换算法

替换时机：发生块失效，并且可以装入块的cache都已经被装满时

Cache替换算法全部由**硬件**实现

1. **堆栈法**：块总是从栈顶进入，而栈底则是近期最久未被访问的块，将被替换
2. **比较对法**：使用触发器实现，让各个块成对组合，用一个触发器表示一对（两个）块访问的先后顺序；然后把每个对的顺序经门电路计算就可以找到应该被替换的块

显然**比较对法更快**，但更复杂、硬件成本更高：若有$p$个块则需要$p$个与门，$p(p-1)/2$个触发器

### Cache的透明性与性能分析

Cache存储层次对系统程序员和应用程序员都是透明的

#### 写cache

Cache作为主存的副本，有的时候会与主存不一致：

- cpu写了cache但没写主存
- I/O写了主存但没写cache

为了保持Cache与主存的一致性，我们有两种更新算法：

- ==写直达法==WT：cpu写cache时同时写主存
- ==写回法==WB：cpu只写cache，一直到该块被替换时再把修改的内容写回到主存

具体到写Cache时，有两种方法：

- 不按写分配法：在写不命中时，只把要写的字写入主存。在写直达法中采用
- 按写分配法：在写不命中时，还把一个块从主存读入cache。在写回法中采用

#### 预取算法

- 按需取：出现cache不命中时，把下一个块取入cache
- 恒预取：无论是否命中，都把下一个块取入
- 不命中预取：出现cache不命中时，把本块和下一块一起取到cache中

但是采用预取也==不一定能提高命中率==，还要同时考虑块的大小和预取开销

#### 性能影响因素

- 块的大小与数量
- 采用组相联时，组内的块数和组数
- 替换算法
- 地址流
- 预取算法

Cache的命中率随着Cache容量提升而提升，但是有提升的瓶颈（或者叫边界值）

## 虚拟存储器

虚拟存储器由主存储器和联机工作的外存储器（磁盘存储器）共同组成，即虚存=主存+外存

### 虚存管理

#### 段式管理

将程序按逻辑意义分成==段==，按段进行调入、调出和管理

- 每个程序段都从0开始编址，段可长可小
- 每个程序段可以映像到主存的任意位置
- **每道程序都有一张段表**，用于指定每段的基地址；**段表的地址由基址寄存器指定**

![image-20230328100154525](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303281001595.png)

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303281005181.png" alt="image-20230328100558090" style="zoom:67%;" />

Pros&Cons:

- 模块化性能好，便于共享
- 实现程序的动态链接和调度比较容易
- 地址变换花费时间长
- 对主存的利用率较低

#### 页式管理

将主存空间和程序空间都等分成固定大小的页面，让程序的起点必须处在某页的起始位置。主存上的页称为实页，虚存的页称为虚页，地址映像机构负责转换

页式管理需要一个**页表**来存储实页与虚页的对应关系，以及是否装入等信息

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303281007120.png" alt="image-20230328100759087" style="zoom:67%;" />

- 地址转换较快，主存利用率更高
- 页表很长，而且不适合模块化的管理

#### 段页式管理

程序按结构分段，每段再划分为若干大小相等的页

每道程序因为有多个段，所以需要一张段表，多张页表。虚地址包含用户号、段号、段内页号、页内地址四部分

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202303281012671.png" alt="image-20230328101242633" style="zoom:50%;" />

### 页式虚拟存储系统构成

#### 地址变换

- 实地址$A$由实页号$p$和页内偏移$d$组成
- 虚地址$A_v$由用户号$U$、虚页号$P$和页内偏移$D$组成

1. 内部地址变换：虚页号转换成实页号，然后与页内偏移拼接得到实地址
2. 外部地址变换：查外页表获取磁盘实地址，查实页表看主存是否有空页，之后把页调入主存，得到实地址

#### 页面替换

发生页面失效时，要将一页调入主存；若主存中所有页面都被占用，则必须淘汰一个页面

- 页面失效：该页未装入主存，需从外存中调页（页面失效应该当作一种故障来处理）
- 页面冲突：两个以上的虚页面想要进入主存中的同一个页面位置

页面失效时不一定发生页面冲突，但是页面冲突一定是由页面失效引起

常用的替换算法：

1. FIFO
2. LRU（堆栈型算法）

### 页式虚拟存储器实现时的问题

#### 提高访问速度

两种主要方式：提高命中率或降低访存时间

- ==目录表==：使用一个小容量高速存储器存放页表
- ==快慢表==：优先查快表，查不到再去主存中的慢表中查（快表就是上面的目录表思想）
- ==散列函数==：把相联访问变成按地址访问，来加大快表容量

#### 影响命中率的因素

1. **页面大小**：当页面大小为一个值时，命中率最高
2. **主存容量**：命中率随主存容量提升而单调上升
3. **调度方式**：请求式与预取式。请求式是什么时候用到什么时候调入，这样在一开始会有大量页面失效；预取式就是提前调入再运行，但是也有可能仍然页面失效，做无用功

## 提高存储系统性能

- 双端口存储器：有两组独立的读写控制线路
- 并行主存储器：多体交叉存储器，有三个方案：
  1. 单体多字存储器：一次读出多个存储字，适合连续存放的情况
  2. 多体单字交叉存储器
  3. 多体多字交叉存储器

高位交叉扩大存储器**容量**；低位交叉提高访存**速度**





# Chapter 4&5 中央处理器

## CPU的功能和组成

CPU的**功能**：

- 控制指令的执行顺序
- 产生**控制信号**控制部件工作
- 控制各步操作的**时序**
- **数据处理**：算数操作和逻辑运算

CPU的组成：==数据通路==和==控制器==两部分

- 数据通路：指令执行过程中，数据所经过的路径，包括路径中的部件。它是指令的==执行部件==，包含寄存器、运算部件
- 控制器：对指令进行译码，生成指令对应的控制信号，控制数据通路的动作。是指令的==控制部件==，包含译码器、时序控制等

### 寄存器

CPU中的寄存器用来暂时保存在运算和控制过程中的中间结果、最终结果以及状态、控制信息

分为通用寄存器和专用寄存器，专用寄存器至少要有：程序计数器==PC==、指令寄存器==IR==、存储器地址寄存器==MAR==、存储器数据寄存器==MDR==、状态标志寄存器==PSWR==

## 控制器的组成和实现方法

### 组成

1. 指令部件：取指令并分析指令，包括：PC, IR, ID（指令译码器）, 地址形成部件
2. 时序部件：产生一定的时序信号，包括：脉冲源、启停控制逻辑、节拍信号发生器
3. ==微操作信号发生器==：控制器的核心，把一条指令的取出和执行分解为很多微操作
4. 中断控制逻辑

### 实现

微操作信号发生器

实现方法分为：组合逻辑型、控制逻辑型、组合存储逻辑结合型

## 时序系统与控制方式

### 概念

- 指令周期和机器周期：指令周期是指取指令、分析指令到执行完该指令所需的全部时间，$指令周期=i\times机器周期$
- 节拍：有时要把机器周期分为若干个相等的时间段，即为节拍
- 工作脉冲：在一个节拍内设置若干个工作脉冲，以保证所有触发器稳定且可靠地翻转
- 多级时序系统：机器周期-->节拍-->工作脉冲多级时序

### 控制方式

- 同步控制方式：各指令所需的时序由控制器统一发出，所有微操作都与时钟同步
- 异步控制方式：各部件自己产生自己的时序信号自我控制
- 联合控制方式

### 指令执行

三个核心阶段：==取指令、分析取数、执行==

取指令的公共操作：`(PC)->MAR`；`READ`；`M(MAR)->MDR->IR`；`(PC)+1->PC`

### 指令的微操作序列

实际上，要完成读一个主存中的数据的操作，有以下步骤：

1. 将存储地址的寄存器送至MAR
2. READ
3. 把读出的内容送至MDR，然后再送至其他寄存器



## *微程序控制原理

用程序设计的思想来组织操作控制逻辑，将**控制信号**编码形成==控制字==（微指令），再把这些微指令按时间先后排列起来，存储在一个只读存储器中

1. 微命令和微操作：一条机器指令可以分为一个微操作序列；微命令是控制计算机各部件完成某个基本微操作的命令。**微命令是微操作的控制信号，微操作是微命令的操作过程**
2. 微指令和微地址：微指令是指控制存储器中一个单元的内容；存放控制字的控制存储器的单元地址就是微地址
3. 微周期：读取并执行一条微命令所需要的时间
4. 微程序：与机器周期对应，是一系列微指令的有序集合

![image-20230607092359610](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306070923805.png)

### *微指令编码法

一条微指令至少包含两大信息：![image-20230607094121778](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306070941968.png)

微指令编码法指的就是微操作码的编码方法：

1. 直接控制法：也称不译码法，微操作码中的的每位直接控制对应微命令是否有效
2. 最短编码法：对所有微命令统一编码，每条微指令只定义一个微命令
3. ==字段编码法==：将控制字段分为几个小段，段内采用最短编码法，段间采用直接控制法
   
   - 字段直接编码法：各字段独立定义本字段的微命令，与其他字段无关
   - 字段间接编码法：一个字段和其他字段联合定义
   
   字段编码法的==设计原则==：
   
   1. 互斥的微命令分在同一段内，兼容性的微命令分在不同段内
   2. 每个小段还要留出一个状态，表示本字段不发出任何微命令

### 微程序控制器

#### 基本组成

1. 控制存储器CM（核心部件）：用来存放微程序
2. 微地址寄存器uIR：用来存放从CM中取出的微指令
3. 微地址形成部件：产生初始微地址和后继微地址
4. 微地址寄存器uMAR：接受微地址，为在CM读取指令做准备

#### 工作过程

微程序控制器的工作过程就是一条条机器指令的执行过程：

1. 执行取指令公操作
2. 由操作码产生入口地址，并送入uMAR
3. 从CM中逐条取出对应的微指令并执行

#### 微程序地址

- 初始微地址：由机器指令的==操作码==字段指出各段微程序的入口地址（初始微地址）

  由机器指令的操作码转换成初始微地址的方法有三种：一级功能转换；二级功能转换；PLA功能转换

- 后继微地址：增量方式（顺序-转移）和断定方式（给定+测试）

#### 微程序设计方法

- 水平型微指令：一次能定义并执行多个微命令，并行性高，灵活性强
- 垂直型微指令：一次只能执行一个微命令，编程简单，微指令字较短

## 流水线

### 基本概念

#### 流水线技术

流水线技术：将指令的执行过程分解为==多个子过程==，并让每个子过程分别由专用的部件完成，这些功能部件可以同时工作，从而实现多条指令的并行执行，减少多条指令或一段程序的完成时间

- 空间并行性：设置多个独立的操作部件，多操作部件处理机、超标量
- 时间并行性：流水线，流水线/超流水线处理机

流水线是基于==时间重叠==的并行处理技术，**不能加快一条指令的执行**，但是能加快多条指令的执行

1. 只有==连续==提供==同类==任务才能充分发挥流水线效率
2. 流水线中的每一段都需要设置一个==流水寄存器==
3. 各段的时间应尽可能相等
4. 流水线有装入时间和排空时间

#### 流水线分类

部件级/处理机级/处理机间级（流水线级别）；单功能/多功能（流水线面向功能）；静态/动态（是否允许联结多种功能）；线性/非线性（是否有反馈信号），非线性流水线需要用流水线连接图和流水线预约表共同表示

### *流水线性能

提升性能的方法：

1. 细分瓶颈过程
2. 重复设置瓶颈功能段，让他们并行交叉工作

#### 性能指标

- **吞吐率**：流水线单位时间里能流出的任务数或结果数
- **加速比**：流水线速度与等效的非流水线速度之比，$\large S_p=\frac{T_{非流水}}{T_{流水}}$
- **效率**：又称设备时间利用率，是流水线中的设备实际使用时间占整个运行时间之比

### *流水线调度

==资源冲突==：几个任务争用一个功能段的现象

线性流水线因为没有反馈，所以不会发生冲突，只需间隔固定的时间输入任务即可

但是非线性流水线段间有反馈回路，一个任务在流水执行的全过程中，可能会多次通过同一段，或越过某些段。如果每拍都向流水线中输入数据，就会发生资源冲突

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202305091056008.png" alt="image-20230509105646821" style="zoom:50%;" />

那么此时就引入了调度问题——间隔几拍向流水线中输入数据才能既不冲突，又能获得比较高的吞吐率？

#### 二维预约表

假设有一个由$K$段组成的单功能非线性流水线，每个任务通过流水线需要$N$拍。若一个任务在第$n$拍时需要用到第$k$段，那么就在表中的$(n,k)$处置✅。例如一个5段9拍的二维预约表：

|      | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| S1   | ✅    |      |      |      |      |      |      |      | ✅    |
| S2   |      | ✅    | ✅    |      |      |      |      | ✅    |      |
| S3   |      |      |      | ✅    |      |      |      |      |      |
| S4   |      |      |      |      | ✅    | ✅    |      |      |      |
| S5   |      |      |      |      |      |      | ✅    | ✅    |      |

#### 调度方法

1. 根据预约表可以得出一个任务使用各功能段所需间隔的拍数，构建延迟==禁止向量F==

   将流水线中所有各功能段对一个任务流过时会产生争用的节拍间隔数汇集在一起，比如上面的预约表的禁止向量$F=\{1,5,6,8\}$，这些间隔节拍禁止使用

2. 将禁止向量(或禁止表)转换成m位的、用二进位表示的==初始冲突向量C==

   例子的冲突向量$C=10110001$

3. 计算流水线的新的冲突向量

   对于每个冲突向量，对其不断右移，**每移出一个0之后就和初始冲突向量作一次按位或**，直至求到这种运算的==闭包==

4. 构造用冲突向量表示的流水线状态图

   对于3中得到的所有冲突向量，每个向量都是一个状态，状态转移条件即为前状态右移几位之后作按位或能得到后状态。如：

   ![image-20230509155324093](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202305091553236.png)

5. 确定调度方案

   从状态图中的初始状态出发，找到一个间隔拍数呈周期性重复的方案，并按 此方案进行调度，就不会发生功能段冲突。如上图的调度方案有：(2,7); (2,2,7); (3,4,7)等等。需要从诸多调度方案中挑选出平均延迟最小的，吞吐量最大的
   
   有些方案可能最大吞吐量是一样的，但是在效率或者真实的吞吐量方面上有细微差别，选择方案时要综合考虑

### 流水线相关处理

相关：相邻或临近的两条指令因存在某种关联，它使得指令序列中下一条指令无法按照设计的时钟周期开始执行

#### 局部性相关（数据相关）

原因：当机器执行多条指令时，这些指令对==同一存储单元==“先写后读”导致（联想csapp数据相关）

解决方法：推后读（将读的操作延迟）；设置相关专用通路（同csapp中解决方法）

#### 全局性相关（控制相关）

原因：由分支转移指令引起的相关（联想csapp控制相关）

解决方法：尝试判断正确的转移分支

- 猜测法，保证猜错时可恢复分支点原先的现场
- 加快和提前形成条件码
- 延迟转移
- 加快短循环程序的处理

|               局部性相关               |            全局性相关            |
| :------------------------------------: | :------------------------------: |
|  指令相关、主存数相关、寄存器组相关等  |                                  |
| 只影响数条指令，不影响指缓中预取的指令 |  影响后续指令、指缓中预取的指令  |
| 同步流动由WR引起；异步流动由WW、RW引起 |       一般由转移或中断引起       |
|                                        | 使流水线断流，使吞吐率和效率下降 |

#### 流水线的中断处理

中断会使流水线断流，它不经常发生，不可预测，一旦进入中断可能持续很长时间

流水机器中断的处理主要是==断点现场的保护与恢复==

- 不精确断点法：允许已经在流水线中的指令执行完毕再进入中断，中断处理简单但是调试困难
- ==精确断点法==：不论指令i在流水线哪一段发生中断，只保存第i条指令的现场

### 向量流水处理与向量机

向量的特点：元素之间无相关，一般对元素执行相同类型的操作

#### 向量的处理方式

要根据向量运算的特点和向量处理机的类型选择处理方式

- 水平处理：标量机的处理法，向量机不用这个
- 垂直处理：以**向量为单位**计算，只要能提供连续输入就能获得高吞吐率，缺点是对存储器要求较高，可以通过采用多体交叉存储或设置向量寄存器组来解决这一问题
- 分组处理：用于寄存器--寄存器结构的向量处理机中，当向量长度大于向量寄存器长度n时，进行分组处理；组内纵向处理，组间横向处理

#### 向量流水处理机

向量流水处理机=向量数据表示+流水线处理

- $V_i$冲突：除相关情况外，并行工作的指令中使用了相同的向量$V_i$
- 功能部件冲突：同一个功能部件被一条以上的要求并行工作的向量指令所使用

### 超标量与超流水

#### 超标量

本质是**在不同的流水线执行不相关指令的能力**

度为$m$的超标量处理机采用$m$流水线，在每个$\Delta t$时间内同时解释完$m$条指令。以增加硬件资源为代价获取处理机性能，利用的是空间并行性

- 单发射处理机：每个周期只操作一条指令
- 多发射处理机：每个周期同时操作多条指令

**一个时钟周期内能够同时发射多条指令的处理机称为超标量处理机**，必须有两条或两条以上能够同时工作的指令流水线

指令集并行度为$(m,1)$，$k$段流水线的超标量处理机上，执行$N$条指令所用的时间为$T(m,1)=(k+\frac{N-m}{m})\Delta t$；相比单流水线标量处理机的加速比为$S(m,1)=\frac{m(k+N-1)}{mk+N-m}$

#### 超流水

**一个周期内能分时发射多条指令的处理机称为超流水线处理机**，通过硬件部件充分重叠工作来提高处理机性能，利用的是时间并行性。

每隔$1/n$个时钟周期发射一条指令，流水线周期为$1/n$个时钟周期

指令并行度为$(1,n)$，$k$段流水线的超流水线处理执行N条指令所用的时间为$T(1,n)=(k+\frac{N-1}{n})\Delta t$，加速比为$S(1,n)=\frac{n(k+N-1)}{nk+N-1}$

#### 超标量超流水

指令并行度为$(m,n)$，$k$段流水线的超标量超流水线处理机执行$N$条指令所用的时间为==$\large T(m,n)=(k+\frac{N-m}{mn})\Delta t$，加速比为$\large S(m,n)=\frac{mn(k+N-1)}{mnk+N-m}$==



#### 性能比较

- 超流水线的启动延迟比超标量处理机大
- 条件转移造成的损失，超流水线要比超标量大
- 因为超标量重复设置了多个指令执行部件，所以超标量执行指令时出现的冲突会更少

一般来说，并行度m和n都不要超过4



# Chapter 6 输入输出系统

## 概述

### 组成

输入输出系统包括：**输入输出设备**、**设备控制器**及与输入输出操作**相关的软硬件**

### 功能

是对指定的外设进行输入、输出操作，同时也完成许多其他的管理和控制

### 特点

- 异步性：IO设备不使用统一的中央时钟，按自己的时钟工作
- 实时性
- 与设备无关性：IO设备独立于具体设备的标准接口



## 磁盘阵列

### RAID

优点：成本低、功耗小、速率高；提供容错能力

### SSD

SSD由两部分组成：**控制单元**，负责读取、写入资料；**存储单元**：负责存储资料（Flash芯片）

- 优点：读写速度快；低功耗；无噪音；防震抗摔；工作温度范围大；轻便

- 缺点：容量上限低；售价高；寿命问题



## 总线

在大多数小型和微型计算机系统中，计算机的各子系统之间通过总线（Bus）实现连接

### 总线特点

总线是一组能为多个部件==分时共享==的公共信息传送线路

#### 总线事务

通常把在总线上一对设备之间的一次信息交换过程称为一个==总线事务== ，把发出总线事务请求的部件称为==主设备==，与主设备进行信息交换的对象称为==从设备==

总线事务包括两个阶段：地址阶段，数据阶段

#### 总线使用权

因为总线是共享的，所以必须有一个总线控制机构，实现对总线使用的分配与管理

主设备请求并获得总线使用权后，立即开始向从设备进行一次信息传送

通常，将完成一次总线操作的时间称为==总线周期==；总线使用权的转让总发生在总线进行一次数据传送的结束时刻



### 总线数据宽度

数据宽度是I/O设备取得I/O总线后所传送数据的总量。对于不同速度的设备，有不同的数据宽度，比如**单字**宽度、**变长块**宽度、**定长块**宽度



### 总线线数

总线需要有很多物理线路，总线的线数越多，成本越高、干扰越大、可靠性越低，传送速度和流量越高。因此，在满足性能要求的情况下，应尽量减少总线的线数



### *总线性能指标

#### 总线宽度

总线宽度指的是总线的线数，它决定了总线所占的物理空间和成本

> 例如：20位地址线允许寻址的主存空间大小为$2^{20}$个主存单元

#### 总线带宽

总线的最大数据传输速率，即每秒传输的字节数
$$
总线带宽=总线宽度\times总线频率
$$

#### 其他指标

总线负载、总线复用、总线猝发传输



### 总线控制

为了保证同一时刻**只有一个申请者**使用总线，总线控制机构需要按照一定的优先次序来决定哪个部件首先使用总线。只有获得使用权的部件才能开始数据传输

#### 集中仲裁

总线控制逻辑集中在一处

1. 链式查询：总线控制器使用三根控制线与所有部件和设备相连，包括总线请求BR、忙BS、批准BG。这样做无法更改查询优先级
2. 计数器定时查询：有公共的BR线和BS线，还需要一些线来控制优先次序。对于$n$个部件，需要$2+\lceil log_2n\rceil$根线
3. 独立请求：每一个部件都有一对BR和BG。对于$n$个部件，需要$2n+1$根线

#### 分布仲裁

总线的控制逻辑分散在连接于总线上的各个部件或设备中

1. 自举分布式：优先级固定，需要控制权的设备在各自的请求线上送出请求信号。如果检测到没有优先级更高的设备正在请求使用总线，则使用总线并通过总线忙信号阻止其他设备使用总线
2. 冲突检测分布式：如果发现冲突则等待一段随机的时间再重新使用，联想计网中的Ethernet
3. 并行竞争分布式：总线上的每个设备都有一个唯一的仲裁号，需要使用总线的主控设备把自己的仲裁号发送到仲裁线上，这个仲裁号将用在并行竞争算法中。每个设备根据**仲裁算法**决定在一定时间段后占用总线还是撤销仲裁号



## 6.4 输入输出系统控制

### 概述

主机和外设之间的信息传送控制方式，按照发展的先后次序和主机与外设并行工作的程度，可以分为四种：

1. 程序查询方式：CPU直接控制
2. 程序中断方式：外设在做好输入输出准备时，向主机发中断请求
3. 直接存储器存取方式 DMA：DMA是在主存和外部设备之间开辟的直接数据通路，可以在没有cpu介入完成数据在主存与外设之间的交换
4. I/O通道控制方式：通道是一个具有特殊功能的处理器，可以产生控制信号，实现对外设的统一管理与数据传送

|    控制方式    |                         优点                         |                             缺点                             |         适用场景         |
| :------------: | :--------------------------------------------------: | :----------------------------------------------------------: | :----------------------: |
|    程序查询    |                       控制简单                       |            外设、主机之间不能同时工作，系统效率低            | 实时要求低且不繁忙的系统 |
|    程序中断    | 允许主机和外设同时并行工作，允许一台主机管理多台外设 |              CPU占用高；高速外设可能会丢失信息               |    适用于中、低速外设    |
| 直接存储器存取 |            能保证CPU的高效率和外设的高速             | 只能进行简单的数据传送操作，在数据块传送的起始和结束时还需CPU及中断系统进行预处理和后处理 |      适用于高速外设      |
|  I/O通道控制   |   不论交换信息多少，只打扰CPU两次（启动和停止时）    |                                                              |                          |

### 程序查询方式

CPU在程序中查询外设的工作状态，如果外设尚未准备就绪，CPU就等待，只有外设已作好准备，CPU才能执行I/O指令，这就是程序查询方式

#### 工作流程

使用查询方式，至少要5个指令才能完成一次数据传送，包括下面的12356

1. 预置传送参数
2. 向I/O接口发命令字来启动外设
3. 从I/O接口取回状态字
4. 查询外设标志
5. 传送数据
6. 修改传送参数
7. 判断传送是否结束

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202305131436628.png" alt="image-20230513143646441" style="zoom:33%;" />



### *程序中断方式

中断系统在cpu中会配置==**中断机构**==，外设接口配置==**中断控制器**==，软件上设计==**中断服务程序**==

#### 中断源和中断请求

==中断源==是指中断的来源，即任何引起计算机中断的事件

多个中断请求触发器构成一个中断请求寄存器，其中每一位对应一个中断源，中断请求寄存器的内容称为中断字或中断码，**中断字中为“1”的位就表示对应的中断源有中断请求**

#### 中断请求信号的传送

- 独立请求线：每个中断源单独设置请求线，独立发送中断请求信号
- 公共请求线：有一根公共请求线
- 二维结构：将中断请求线连成二维结构，同一优先级的中断源采用一根公共请求线

#### 中断优先级

- 软件判优法
- 硬件判优电路

#### CPU响应中断的条件

1. cpu接收到中断请求信号
2. cpu允许中断
3. 一条指令执行完毕

#### 中断隐指令

CPU响应中断之后，经过某些操作，转去执行中断服务程序。 这些操作是由硬件直接实现的，我们把它称为==中断隐指令==。中断隐指令并不是指令系统中的一条真正的指令，它**没有操作码**，所以中断隐指令是一种不允许、也不可能为用户使用的特殊指令。它包括以下操作：

1. 保存断点
2. 暂不允许中断
3. 引出中断服务程序

#### 中断周期

1. `0->MAR`，将特定地址0送至MAR；如果要把断点存入堆栈，则改为`SP->MAR`
2. `(PC)->MDR`，将PC内容送至MDR
3. `Write`，启动存储器写操作
4. `MDR->M(MAR)`，将MDR的内容写入MAR指示的主存单元
5. `向量地址->PC`， 把向量地址形成部件的输出送入PC，为转入中断服务程序做准备
6. `0->EINT`，关中断，将中断允许触发器清0

####  进入中断服务程序

CPU决定响应中断之后，向中断源发出中断响应信号；中断源接到中断响应信号后就通过自己的向量地址发生器向CPU发送向量地址，这个向量地址有两种情况：

- 向量地址是中断服务程序的**入口地址**，直接进入中断服务程序
- 向量地址是**中断向量表的指针**，需要从中断向量表的响应单元中取出中断服务程序的入口地址

#### 中断现场的保护和恢复

使用堆栈保存通用寄存器等硬件的信息

#### 中断嵌套

中断嵌套的层次可以有多层， 越在里层的中断越急迫，优先级越高，因此优先得到CPU的服务。需要CPU能保护多个断点，并且进入中断服务程序后仍然保持开中断

#### 开/关中断

由中断允许触发器控制，置1则开中断，置0则关中断

==开中断的情况==：

- 中断服务程序执行完毕，恢复中断现场之后
- 多重中断的情况下，保护中断现场之后

==关中断的情况==：

- 响应某一级中断请求，不再允许被其他中断请求打断时
- 在中断服务程序的保护和恢复现场之前

#### 中断屏蔽

用程序的方式有选择地封锁部分中断，可以使用掩码按位与来实现

不同的优先级的中断源可以有不同的屏蔽字，以防止被优先级低的中断打断

#### *中断升级

升级是将级别较低的中断源变成较高级别，改变中断的==处理次序==

升级的方法很简单，就是**改写中断源的屏蔽字**

> ![image-20230621211819532](https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306212118743.png)

#### 中断全过程

1. 中断请求
2. 中断判优
3. 中断响应
4. 中断处理：执行中断服务程序，分为保护现场、处理中断和恢复中断
5. 中断返回

### DMA

程序查询还是中断需要CPU执行程序来完成，而直接存储器访问DMA方式是在外设和主存储器之间开辟一条==直接数据通道==，不需要CPU程序也能传送数据

#### 特点

- 主存既可以被CPU访问，又可以被外设访问
- 主存地址、传送数据计数由硬件实现
- 传送速度快，和CPU并行工作
- DMA开始前和结束后需要通过程序和中断方式进行预处理和后处理

#### 与中断的区别

- 中断需要保护和恢复现场；DMA除预处理和后处理以外，不需要CPU
- 中断只能发生在每条指令执行完毕时；DMA可以发生在**每个机器周期结束时**
- DMA的数据传送速率更高
- DMA的请求优先级高于中断请求
- 中断可以处理异常事件；DMA局限于传送信息块

#### DMA控制器功能

在传送数据期间，代替CPU工作，可以向CPU发出总线请求、自动修改计数值、发出读写等控制信号、执行数据传送操作、报告DMA操作结束等

#### DMA控制器基本组成

- 主存地址计数器：存放主存中要交换数据的地址
- 传送长度计数器：记录传送数据块的长度，为0时表示数据传输完毕
- 数据缓冲寄存器：外设的数据先送入缓冲，再送入主存
- DMA请求触发器
- 控制/状态逻辑
- 中断机构：向CPU提出中断请求，用于后处理

#### DMA传送方法

1. CPU停止访问主存法
2. 存储器分时法：把原来的一个存取周期分为两片，一片给CPU，一片给DMA，令二者交替访问。如果要维持CPU访存速度不变，就需要主存工作速度提高一倍
3. 周期挪用法：一旦外设有DMA请求并获得CPU批准后，CPU让出一个周期的总线控制权，由DMA控制器控制系统总线，进行数据传输，然后再把控制权交回CPU；重复上述过程直至数据块传输完毕

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306071935327.png" alt="image-20230607193504111" style="zoom:33%;" />

#### DMA传送过程

1. DMA预处理
2. 数据传送
3. DMA后处理

### I/O通道控制方式

通道是DMA方式的进一步发展，二者区别主要在于：通道是一个具有特殊功能的处理器，可以同时控制多台不同类的设备；通道由更强的独立处理数据输入/输出的功能

#### 通道的功能

- 接受CPU的指令，按要求与指定的外设进行联系
- 取通道指令，向外设发送命令
- 数据传送
- 向CPU报告外设和自身的中断请求
- 将外设的状态信息送至主存的制定单元供CPU使用





# Chapter 7 多处理机

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306071944748.png" alt="image-20230607194404537" style="zoom: 33%;" />

## 多处理机概念

### 定义

多处理：在多个处理机上运行同一道程序或作业的不同任务。可以串行，也可以并行

多处理机：由两台及以上处理机组成的计算机系统，实现作业任务指令数据等各个级别的并行，属于MIMD

### 分类

按**并行实现技术**分类：

- 同构型：基于资源重复
- 异构型：基于时间重叠
- 分布式

根据**耦合度**分类：

- 紧耦合多处理机：直接耦合系统，通过公共硬件通信，一般将其称为多处理机
- 松耦合多处理机：间接耦合系统，通过通道、通信线路或网络进行通信，一般将其称为多计算机

### 主要技术问题

- 结构灵活性与通用型
- 进程通信方法：共享内存、互连网络、消息传递机制
- 运行模型：数据并行+处理并行
- 并行性表达
- 并行算法

## 多处理机结构

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306081832701.png" alt="image-20230608183250526" style="zoom: 25%;" />

从**存储器**的分布和使用上看，多处理机系统分类两种结构：

- 共享存储器结构：还可以细分为UMA结构和NUMA结构
- 分布式存储器结构

### 共享存储器结构

各处理机通过互联网络**共享存储器和I/O设备**，并通过共享存储器相互联系。不过这也引入了Cache的一致性问题

#### UMA结构

均衡存储器访问结构。各处理机对存储器的访问时间、访问功能相同。这种结构的处理机称为**对称多处理机SMP**

互联网络一般是总线，也可以是交叉开关或多级交换网络

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306072128634.png" alt="image-20230607212857416" style="zoom:33%;" />

#### NUMA结构

非均衡存储器访问结构。各处理机拥有自己的本地存储器，可以独立工作，也可以借助互联网络、通过消息传递机制相互通信

<img src="https://lbw-img-lbw.oss-cn-beijing.aliyuncs.com/img/202306081826948.png" alt="image-20230608182652706" style="zoom:33%;" />

#### ccNUMA

高速缓存一致性非均匀存储访问，在NUMA多处理机中，若**各处理机Cache内容一致**，则将其称为ccNUMA

使用基于==目录==的高速缓存一致性协议

#### COMA

仅用高速缓存存储器结构，是NUMA的特例，将NUMA中的分布存储器换成了Cache

各处理机节点上没有主存，没有存储层次结构，仅有Cache

### 分布式存储器结构

NORMA，非远程存储访问：各处理机拥有私有的本地存储器，在本地操作系统控制下独立工作；各处理机借助互联网络，通过消息传递机制相互通信，实现数据共享

大规模并行处理机MPP和机群等采用这种结构

#### 大规模并行处理机 MPP

以定制的高带宽、低延迟的高速互联网络互联

是一种异步的MIMD机器

#### 机群 COW/NOW

通过一组松散耦合的计算机软件/硬件连接起来，高度紧密地协作完成计算工作的计算机系统

是非均匀存储访问的MIMD型的分布式存储并行计算机

## 多核处理器

多核处理器是多处理机的一种特殊形式，即一个芯片上的SMP

### 硬件多线程

为每个线程提供单独的通用寄存器组和程序计数器等，线程切换时，处理器只需要激活选中的寄存器，达到快速切换线程的目的，这种方式叫做硬件多线程

### 线程切换

- 细粒度多线程：处理器每个时钟周期轮流发射不同线程的指令
- 粗粒度多线程：仅在一个线程出现较大开销的阻塞时，才切换线程
- 同时多线程：多个线程的指令被同时发射

### 结构设计

- 同构/异构
- 核的数量
- Cache的设置与访问
- 核间通信技术

## 多处理机的多Cache一致性

如果一道程序的任何运行结果都与按假定序列执行的结果一样，则称多处理机存储器是一致性的

所有存储器访问的执行都必须保持所有各个程序的次序
